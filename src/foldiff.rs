use crate::hash;
use crate::{cliutils, zstddiff};
use anyhow::{bail, ensure, Context, Result};
use derivative::Derivative;
use indicatif::ProgressBar;
use rmp_serde::{Deserializer, Serializer};
use serde::{de::IgnoredAny, Deserialize, Serialize};
use std::collections::BTreeMap;
use std::fs::File;
use std::io::{copy, Read, Seek, Write};
use std::path::{Path, PathBuf};

static VERSION_NUMBER: [u8; 4] = [0x24, 0x09, 0x06, 0x01]; // 2024-09-06 r1

// a relatively convenient and boring default type that implements Read+Write+Seek
type DefaultReadWriteSeek = std::io::Cursor<&'static [u8]>;

/// Messagepack manifest structure stored in the diff file
#[derive(Clone, Debug, Serialize, Deserialize, Derivative)]
#[derivative(Default)]
pub struct DiffManifest {
	#[derivative(Default(value="VERSION_NUMBER"))] // this really should be in std
	version: [u8; 4],
	untouched_files: Vec<HashAndPath>,
	deleted_files: Vec<HashAndPath>,
	new_files: Vec<NewFile>,
	duplicated_files: Vec<DuplicatedFile>,
	patched_files: Vec<PatchedFile>,
}

/// An in-memory representation of a diff, used for the diff creation process
#[derive(Clone, Debug, Default)]
pub struct DiffingDiff {
	// manifest: DiffManifest,
	blobs_new: Vec<PathBuf>,
	blobs_patch: Vec<(PathBuf, PathBuf)>, // old, new
	old_root: PathBuf,
	new_root: PathBuf,
	files: BTreeMap<u64, DiffingFileData>,
	// for efficient lookups, must be kept in sync
	file_paths_old: BTreeMap<PathBuf, u64>,
	file_paths_new: BTreeMap<PathBuf, u64>,
}

/// the looked up value of DiffingDiff::files entries
#[derive(Clone, Debug)]
struct DiffingFileData {
	paths_old: Vec<PathBuf>,
	paths_new: Vec<PathBuf>,
	inferred_mime: Option<&'static str>,
}

/// An in-memory representation of a diff, used for the applying process
#[derive(Clone, Debug, Default)]
pub struct ApplyingDiff<R: Read+Seek = DefaultReadWriteSeek> {
	manifest: DiffManifest,
	blobs_new: Vec<u64>,   // offset into diff file
	blobs_patch: Vec<u64>, // offset into diff file
	read: R, // the diff file stream
	old_root: PathBuf,
	new_root: PathBuf,
}

// untouched files, deleted files
type HashAndPath = (u64, String);

#[derive(Clone, Debug, Serialize, Deserialize, Default)]
struct NewFile {
	hash: u64,
	index: u64,
	path: String,
}

#[derive(Clone, Debug, Serialize, Deserialize, Default)]
struct DuplicatedFile {
	hash: u64,
	old_paths: Vec<String>,
	new_paths: Vec<String>,
}

#[derive(Clone, Debug, Serialize, Deserialize, Default)]
struct PatchedFile {
	old_hash: u64,
	new_hash: u64,
	index: u64,
	path: String,
}

impl DiffManifest {
	/// checks if this diff state contains a reference to the given path in the old folder
	/// this does not check if the hash matches, but does return it if present
	fn contains_file(&self, root_is_new: bool, path: &Path) -> Option<u64> {
		if !root_is_new {
			for (h, p) in &self.deleted_files {
				if Path::new(p) == path {
					return Some(*h);
				}
			}
		}

		for (h, p) in &self.untouched_files {
			if Path::new(p) == path {
				return Some(*h);
			}
		}

		if root_is_new {
			for nf in &self.new_files {
				if Path::new(&nf.path) == path {
					return Some(nf.hash);
				}
			}
		}

		for dup in &self.duplicated_files {
			let paths = if root_is_new { &dup.new_paths } else { &dup.old_paths };

			if paths.iter().any(|p| Path::new(p) == path) {
				return Some(dup.hash);
			}
		}

		for pat in &self.patched_files {
			if Path::new(&pat.path) == path {
				return Some(if root_is_new { pat.new_hash } else { pat.old_hash });
			}
		}

		None
	}

	/// checks if the given path is present in the diff and verifies that it matches the expected hash
	/// if this returns false, the directory structure on disk does not match that dictated by the state
	fn verify_contains(&self, root_is_new: bool, path: &Path, root: &Path) -> Result<Option<bool>> {
		if let Some(hash) = self.contains_file(root_is_new, path) {
			let hash_actual = hash::hash_file(&root.join(path))?;

			Ok(Some(hash == hash_actual))
		}
		else {
			Ok(None)
		}
	}
}

impl DiffingDiff {
	pub fn new(old_root: PathBuf, new_root: PathBuf) -> Self {
		Self {
			old_root,
			new_root,
			..Default::default()
		}
	}

	/// generates the on-disk manifest format from the in-memory working data
	pub fn generate_manifest(&self) -> DiffManifest {
		// generally, the on-disk manifest is a really annoying data structure for building diffs
		// so instead, we work with a map from hash to file data, as if every file was a duplicated one
		// this function will figure out which files fall into which category,
		// and figure out what blobs must be generated by write_to, and generate the manifest.

		todo!()
	}

	/// handles finalising an in-memory diffing state to disk
	pub fn write_to(&self, writer: &mut (impl Write + Seek)) -> Result<()> {
		writer.write_all("FLDF".as_bytes())?;

		let mut serializer = Serializer::new(&mut *writer); // lol re-borrowing is goofy but sure
		self
			.generate_manifest()
			.serialize(&mut serializer)
			.context("Failed to serialize diff format into file")?;
		drop(serializer); // this drops here anyway, but is load-bearing, so make it explicit

		// write new files
		writer.write_all(&(self.blobs_new.len() as u64).to_be_bytes())?;

		for path in &self.blobs_new {
			let mut f =
				File::open(path).context("Failed to open file while copying newly added files")?;
			let len = f.metadata()?.len(); // this better be accurate lol

			writer.write_all(&len.to_be_bytes())?;
			let bytes = copy(&mut f, writer)?;

			if bytes != len {
				bail!(
					"Bytes written did not match expected file length whn writing newly added file '{}'",
					path.to_str().unwrap_or("<invalid unicode>")
				);
			}
		}

		// write patches
		writer.write_all(&(self.blobs_patch.len() as u64).to_be_bytes())?;
		//writer.write_all(&0u64.to_be_bytes())?;

		// perform diffing
		for (old_p, new_p) in &self.blobs_patch {
			let mut old = File::open(old_p).context("Failed to open old file for diffing")?;
			let mut new = File::open(new_p).context("Failed to open new file for diffing")?;

			let ol = old.metadata()?.len();
			let nl = new.metadata()?.len();

			zstddiff::diff(&mut old, &mut new, &mut *writer, None, Some(ol), Some(nl))
				.context("Failed to perform diff")?;
		}

		Ok(())
	}

	pub fn write_to_file(&self, path: &Path) -> Result<()> {
		// create file
		let mut f = File::create_new(path).context("Failed to create file to save diff")?;

		self.write_to(&mut f)
	}

	/// adds a new file to the diff
	/// you should not pass a file that is already in the diff - this will return an Err
	fn add_file(&mut self, in_new: bool, path: &Path) -> Result<()> {
		// check if the path is already there
		let paths = if in_new { &mut self.file_paths_new } else { &mut self.file_paths_old };
		if paths.contains_key(path) {
			bail!("Attempting to add a file to the diff that already exists")
		}

		let root = if in_new { &self.new_root } else { &self.old_root };

		// first, hash it
		let resolved_path = root.join(path);
		let hash = hash::hash_file(&resolved_path)?;

		// get working state
		if let Some(state) = self.files.get_mut(&hash) {
			// add our path
			let state_paths = if in_new { &mut state.paths_new } else { &mut state.paths_old };
			state_paths.push(path.to_path_buf());
			paths.insert(path.to_path_buf(), hash);
		}
		else {
			// perform file type inference
			let inferred_type = infer::get_from_path(&resolved_path).context("Failed to infer file type")?.map(|t| t.mime_type());

			let new_state = DiffingFileData {
				inferred_mime: inferred_type,
				paths_old: if !in_new { vec![path.to_path_buf()] } else { vec![] },
				paths_new: if in_new { vec![path.to_path_buf()] } else { vec![] }
			};

			paths.insert(path.to_path_buf(), hash);

			self.files.insert(hash, new_state);
		}

		Ok(())
	}

	pub fn scan(old_root: PathBuf, new_root: PathBuf) -> Result<Self> {
		let mut new_self = Self::new(old_root, new_root);

		let bar = cliutils::create_spinner("Scanning old files");
		new_self.scan_internal(Path::new(""), false, Some(&bar))?;
		cliutils::finish_spinner(&bar);

		let bar = cliutils::create_spinner("Scanning new files");
		new_self.scan_internal(Path::new(""), true, Some(&bar))?;
		cliutils::finish_spinner(&bar);

		Ok(new_self)
	}

	fn scan_internal(&mut self, dir: &Path, new: bool, spinner: Option<&ProgressBar>) -> Result<()> {
		let root = if new { &self.new_root } else { &self.old_root };
		// we need to clone this, aw
		let root = root.clone();

		// read all files in the root
		let entries = std::fs::read_dir(root.join(dir)).with_context(|| format!("Failed to read dir while scanning {dir:?}"))?;

		for entry in entries {
			let entry = entry.with_context(|| format!("Failed to read entry while scanning {dir:?}"))?;

			// tick!
			if let Some(s) = spinner {
				s.inc(1);
			}

			// are we a directory or a file?
			let ftype = entry.file_type().context("While reading entry type")?;
			if ftype.is_symlink() {
				bail!("Entry at '{:?}' is a symlink, bailing", entry.path());
			}
			if ftype.is_dir() {
				// recurse
				self.scan_internal(&entry.path(), new, spinner)?;
			}
			else {
				// file found!
				// strip the root off the front of the path
				// else we get errors in add_file
				let path = entry.path();
				let path = path.strip_prefix(&root)?;
				self.add_file(new, path).context("While adding file to diff")?;
			}

			// sleep for progress bar testing
			//std::thread::sleep_ms(600);
		}

		Ok(())
	}
}

impl ApplyingDiff {
	/// handles initialising an in-memory applying state from disk
	fn read_from(reader: &mut (impl Read + Seek)) -> Result<Self> {
		// check magic bytes
		let mut magic = [0u8, 0, 0, 0];
		reader
			.read_exact(&mut magic)
			.context("Failed to read while creating diff format")?;
		ensure!(
			magic == "FLDF".as_bytes(),
			"Magic bytes did not match expectation ({magic:x?} instead of 'FLDF')"
		);

		// deserialize msgpack data
		// this better understand when to stop reading lol
		let mut deserializer = Deserializer::new(&mut *reader);
		let manifest =
			DiffManifest::deserialize(&mut deserializer).context("Failed to deserialize diff format")?;
		drop(deserializer); // this drops here anyway, but is load-bearing, so make it explicit

		// check version
		ensure!(
			manifest.version == VERSION_NUMBER,
			"Did not recognise version number {:x?}",
			manifest.version
		);

		// create self
		let mut new_self = Self::default();
		new_self.manifest = manifest;

		let mut new_blob_count = [0u8, 0, 0, 0, 0, 0, 0, 0];
		reader
			.read_exact(&mut new_blob_count)
			.context("Failed to read new file count")?;
		let new_blob_count = u64::from_be_bytes(new_blob_count);

		for _ in 0..new_blob_count {
			// keep track of the offset
			new_self.blobs_new.push(reader.stream_position()?);

			// read blob length
			let mut len = [0u8, 0, 0, 0, 0, 0, 0, 0];
			reader
				.read_exact(&mut len)
				.context("Failed to read new file length")?;
			let len = u64::from_be_bytes(len);

			// keep track of the offset
			new_self.blobs_new.push(reader.stream_position()?);
			// jump to next file
			reader
				.seek_relative(len.try_into()?)
				.context("Failed to seek while skipping new file")?;
		}

		let mut patched_blob_count = [0u8, 0, 0, 0, 0, 0, 0, 0];
		reader
			.read_exact(&mut patched_blob_count)
			.context("Failed to read patched file count")?;
		let patched_blob_count = u64::from_be_bytes(patched_blob_count);

		for _ in 0..patched_blob_count {
			// keep track of the offset
			new_self.blobs_new.push(reader.stream_position()?);

			// read through array
			// this is not that efficient but oh well
			let mut deser = Deserializer::new(&mut *reader);
			// lol name collision
			serde::Deserializer::deserialize_any(&mut deser, IgnoredAny)
				.context("Failed to read through patched file data")?;
		}

		Ok(new_self)
	}

	fn read_from_file(path: &Path) -> Result<Self> {
		let mut f = File::open(path).context("Failed to open file to read diff")?;

		Self::read_from(&mut f)
	}

	// TODO: applying functionality

	fn apply(&mut self, old_root: PathBuf, new_root: PathBuf) -> Result<()> {
		self.old_root = old_root;
		self.new_root = new_root;

		todo!()
	}
}